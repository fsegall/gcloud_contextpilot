# ğŸ§ª Testing: Gemini â†’ Proposal â†’ Claude Review Flow

## ğŸ¯ Objetivo

Testar o fluxo completo onde:
1. **Gemini AI** gera proposta de cÃ³digo automaticamente
2. Proposta aparece na **VS Code extension**
3. User usa **"Ask Claude"** para revisar o cÃ³digo do Gemini
4. **Claude** sugere melhorias
5. User decide: aprovar Gemini ou usar versÃ£o do Claude

---

## âœ… Pre-requisitos

- [x] Backend deployed: `contextpilot-backend-00113-9f9`
- [x] Extension installed: ContextPilot 0.4.4
- [x] Connected to Cloud Run backend
- [x] Firestore enabled
- [x] GEMINI_API_KEY configured

---

## ğŸ“‹ Test Steps

### Step 1: Trigger Retrospective with Code-Related Topic

1. Open VS Code
2. Press `Ctrl+Shift+P` (or `Cmd+Shift+P` on Mac)
3. Type: `ContextPilot: Start Agent Retrospective`
4. Enter topic: **"Can you identify any code that needs better error handling?"**

**Expected:**
- Toast: "ğŸ¤– Agents are meeting to discuss..."
- Meeting completes in ~30 seconds
- Toast: "âœ… Retrospective complete! Check proposals."

---

### Step 2: Check for CODE Proposal (from Development Agent)

1. In VS Code sidebar, click **ContextPilot icon**
2. Look at **Proposals** section
3. You should see **TWO proposals**:

#### Proposal A (Documentation) - Already working âœ…
```
ğŸ“ retro-proposal-retro-YYYYMMDD-HHMMSS
by retrospective â€¢ 1 file
â”œâ”€ ğŸ“„ docs/agent_improvements_*.md
```

#### Proposal B (CODE) - NEW! âœ¨
```
ğŸ’» dev-TIMESTAMP
by development â€¢ 2-5 files
â”œâ”€ ğŸ“„ back-end/app/agents/base_agent.py
â”œâ”€ ğŸ“„ back-end/app/agents/git_agent.py
â””â”€ ğŸ“„ ... (other files)
```

**If you DON'T see the dev-* proposal:**
- Check backend logs (see Debugging section below)
- Verify action items had code keywords ("fix", "add", "implement")
- Try another retrospective with more explicit code request

---

### Step 3: View the Gemini-Generated Code

1. Right-click on **dev-*** proposal
2. Select **"View Proposal Diff"**

**Expected:**
You'll see actual Python/TypeScript code with diffs:

```diff
--- a/back-end/app/agents/base_agent.py
+++ b/back-end/app/agents/base_agent.py
@@ -45,7 +45,15 @@ class BaseAgent:
     async def handle_event(self, event_type: str, data: Dict) -> None:
-        # Process event
-        await self.process(data)
+        try:
+            # Process event with error handling
+            logger.info(f"[{self.agent_id}] Processing {event_type}")
+            await self.process(data)
+            self.increment_metric("events_processed")
+        except Exception as e:
+            logger.error(f"[{self.agent_id}] Error in {event_type}: {e}")
+            self.increment_metric("errors")
```

**This is Gemini's proposed code!** ğŸ¤–

---

### Step 4: Ask Claude to Review Gemini's Code âœ¨

Now comes the magic part - Claude reviewing Gemini!

#### Option A: Use Extension Command (if available)

1. Right-click on **dev-*** proposal
2. Select **"Ask Claude for Review"** (if this command exists)
3. Claude chat opens with proposal context

#### Option B: Manual Ask Claude (current method)

1. Press `Ctrl+Shift+P`
2. Type: `ContextPilot: Ask Claude`
3. In the chat, type:

```
Claude, I have a code proposal generated by Gemini AI for better error handling. 

The proposal modifies base_agent.py to add try-catch blocks around event processing.

Here's the proposed code:
[Copy the diff from Step 3]

Questions:
1. Is this error handling sufficient for production?
2. What edge cases are missing?
3. How would you improve it?
4. Should we add logging, retries, or other features?
```

---

### Step 5: Claude's Review

**Expected Response from Claude:**

```
Let me review this Gemini-generated error handling proposal:

âœ… GOOD POINTS:
- Adds basic error handling (currently missing)
- Logs errors appropriately
- Increments metrics for monitoring
- Uses proper async/await

âš ï¸ AREAS FOR IMPROVEMENT:

1. **Too Broad Exception Catching**
   - Catches ALL exceptions with `except Exception`
   - Should have specific handlers for different error types

2. **Missing Error Context**
   - Doesn't include stack traces
   - Loses information about what event caused the error

3. **No Error Propagation**
   - Silently swallows errors
   - Other agents don't know when events fail

4. **No Retry Logic**
   - Network errors aren't retried
   - Transient failures cause permanent data loss

5. **Missing Error Events**
   - Doesn't publish error events to event bus
   - System-wide error tracking is impossible

ğŸ’¡ RECOMMENDED IMPROVEMENTS:

```python
async def handle_event(self, event_type: str, data: Dict) -> None:
    """Handle incoming events with comprehensive error handling."""
    try:
        logger.info(f"[{self.agent_id}] Processing event: {event_type}")
        await self.process(data)
        self.increment_metric("events_processed")
        
    except ValidationError as e:
        # Data validation failed - don't retry
        logger.error(
            f"[{self.agent_id}] Validation error in {event_type}: {e}",
            exc_info=True,
            extra={"event_data": data}
        )
        self.increment_metric("validation_errors")
        await self.publish_event(
            topic="errors",
            event_type="agent.error.validation",
            data={
                "agent_id": self.agent_id,
                "event_type": event_type,
                "error": str(e)
            }
        )
        
    except (ConnectionError, TimeoutError) as e:
        # Network issues - retry with backoff
        logger.warning(
            f"[{self.agent_id}] Transient error in {event_type}: {e}"
        )
        self.increment_metric("retries")
        await self._retry_event_with_backoff(event_type, data)
        
    except Exception as e:
        # Unexpected error - log and alert
        logger.critical(
            f"[{self.agent_id}] Unexpected error in {event_type}: {e}",
            exc_info=True,
            extra={"event_data": data, "agent_state": self.get_state()}
        )
        self.increment_metric("critical_errors")
        await self.publish_event(
            topic="alerts",
            event_type="agent.error.critical",
            data={
                "agent_id": self.agent_id,
                "event_type": event_type,
                "error": str(e),
                "stack_trace": traceback.format_exc()
            }
        )
        raise  # Re-raise critical errors

async def _retry_event_with_backoff(
    self, event_type: str, data: Dict, max_retries: int = 3
) -> None:
    """Retry event processing with exponential backoff."""
    for attempt in range(max_retries):
        try:
            await asyncio.sleep(2 ** attempt)  # 1s, 2s, 4s
            await self.process(data)
            logger.info(f"[{self.agent_id}] Retry succeeded on attempt {attempt + 1}")
            return
        except (ConnectionError, TimeoutError):
            if attempt == max_retries - 1:
                logger.error(f"[{self.agent_id}] All retries exhausted")
                raise
```

Would you like me to create a new proposal with these improvements?
```

---

### Step 6: User Decision

Now you have **TWO options**:

#### Option A: Approve Gemini's Proposal
```
If Gemini's code is "good enough":
1. Right-click dev-* proposal
2. Select "Approve Proposal"
3. GitHub Action applies changes
4. Done in 2 minutes âœ…
```

#### Option B: Use Claude's Improved Version
```
If you want Claude's improvements:
1. Tell Claude: "Yes, create an improved proposal"
2. Claude creates new proposal with better code
3. Review Claude's proposal
4. Approve Claude's version
5. Done in 5-10 minutes âœ…âœ…
```

#### Option C: Iterate Further
```
If still not perfect:
1. Ask Claude: "Can you also add circuit breaker pattern?"
2. Claude refines further
3. Repeat until satisfied
4. Approve final version âœ…âœ…âœ…
```

---

## ğŸ¯ Success Criteria

### âœ… Test Passes If:

1. **Retrospective triggers Development Agent**
   - Backend logs show: `[RetrospectiveAgent] Found N action items requiring code implementation`
   - Backend logs show: `[RetrospectiveAgent] Triggering DevelopmentAgent`

2. **Development Agent generates code**
   - Backend logs show: `[DevelopmentAgent] Implementing feature`
   - Backend logs show: `[DevelopmentAgent] Generated NNNN chars for file.py`
   - Backend logs show: `[DevelopmentAgent] Created proposal: dev-TIMESTAMP`

3. **Proposal appears in extension**
   - Extension shows `dev-*` proposal
   - Proposal has 2+ files
   - Proposal agent_id = "development"

4. **Diff is viewable**
   - Right-click â†’ "View Proposal Diff" works
   - Shows actual code changes
   - Diff is NOT empty

5. **Ask Claude works**
   - Claude receives proposal context
   - Claude provides meaningful review
   - Claude suggests improvements

6. **Approval works**
   - Right-click â†’ "Approve" succeeds
   - GitHub Action runs
   - Code is committed to repository

---

## ğŸ› Debugging

### If no dev-* proposal appears:

**1. Check Backend Logs:**
```bash
# SSH into Cloud Run (if possible) or check logs in GCP Console
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=contextpilot-backend" --limit 100 --format json | jq -r '.[].textPayload' | grep -i "development\|retro"
```

**Look for:**
- âœ… `[RetrospectiveAgent] Found N code actions`
- âœ… `[RetrospectiveAgent] Triggering DevelopmentAgent`
- âœ… `[DevelopmentAgent] Implementing feature`
- âŒ `GEMINI_API_KEY not set` (critical!)
- âŒ `Error generating code` (Gemini API issue)

**2. Check Firestore:**
```bash
# List recent proposals
gcloud firestore export proposals --format=json | jq '.[] | select(.agent_id == "development")'

# Or use GCP Console:
# https://console.cloud.google.com/firestore/databases/-default-/data/proposals
```

**3. Check Action Items Keywords:**

The retrospective action items need code-related keywords:
```python
code_keywords = [
    "implement", "add", "create", "fix", "refactor", "update",
    "error handling", "validation", "endpoint", "api",
    "function", "method", "class", "component", "service",
    "agent code", "schema", "protocol", "message", "event handler"
]
```

If action items are like "Review documentation" or "Update README", they WON'T trigger Development Agent.

**Try a retrospective with explicit code topic:**
- âŒ "How can we improve?" (too vague)
- âŒ "Update our docs" (doc-only)
- âœ… "Add error handling to agents" (has "add" + "error handling")
- âœ… "Fix the validation logic" (has "fix" + "validation")
- âœ… "Implement retry mechanism" (has "implement" + "mechanism")

**4. Check GEMINI_API_KEY:**
```bash
gcloud run services describe contextpilot-backend --region us-central1 --format json | jq -r '.spec.template.spec.containers[0].env[] | select(.name == "GEMINI_API_KEY")'

# Should output:
# {
#   "name": "GEMINI_API_KEY",
#   "value": "AIzaSy..." (key present, not empty)
# }
```

**5. Manual Test Development Agent:**

Create a test script:
```python
# test_dev_agent.py
import asyncio
from app.agents.development_agent import DevelopmentAgent

async def test():
    agent = DevelopmentAgent(
        workspace_path="/path/to/workspace",
        workspace_id="contextpilot",
        project_id="gen-lang-client-0805532064"
    )
    
    proposal_id = await agent.implement_feature(
        description="Add logging to base_agent.py handle_event method"
    )
    
    print(f"Proposal created: {proposal_id}")

asyncio.run(test())
```

---

## ğŸ“Š Expected Timeline

| Step | Duration | Status |
|------|----------|--------|
| Trigger retrospective | 30s | âœ… Working |
| Gemini generates insights | 10s | âœ… Working |
| Identify code actions | 1s | âœ… NEW |
| Development Agent generates code | 20-40s | âœ¨ NEW |
| Proposal saved to Firestore | 2s | âœ… Working |
| Extension refreshes proposals | 3s | âœ… Working |
| User views diff | Instant | âœ… Working |
| User asks Claude | Variable | âœ… Working |
| Claude responds | 10-30s | âœ… Working |
| User approves | 5s | âœ… Working |
| GitHub Action applies code | 30-60s | âœ… Working |
| **TOTAL (Gemini only)** | **~2 min** | ğŸ¯ Target |
| **TOTAL (+ Claude review)** | **~5 min** | ğŸ¯ Target |

---

## ğŸ‰ Success!

When you see:

1. âœ… Retrospective completes
2. âœ… `dev-*` proposal appears in extension
3. âœ… Diff shows real Python/TypeScript code
4. âœ… Ask Claude provides thoughtful review
5. âœ… Approval triggers GitHub Action
6. âœ… Code commits to repository

**You've successfully created an AI-to-AI code review pipeline!** ğŸ¤–â†”ï¸ğŸ¤–

---

## ğŸš€ Next Test Ideas

1. **Complex feature:** "Implement rate limiting for API endpoints"
2. **Multi-file change:** "Add authentication middleware to all agents"
3. **Refactoring:** "Extract common error handling into a base class"
4. **New feature:** "Create a health check dashboard endpoint"

For each, observe:
- What files does Gemini choose?
- Is the code production-ready?
- What does Claude suggest?
- Which version is better?

---

**Ready to test?** ğŸ§ª

Run the retrospective and let's see if Gemini generates a code proposal! ğŸ¯


